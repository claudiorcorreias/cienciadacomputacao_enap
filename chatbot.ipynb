{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe41788f-168d-4036-a59a-c16cc58f5305",
   "metadata": {},
   "source": [
    "### Código funcional (espera interação do usuário pelo teclado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da5a9b-ac71-413c-8713-f4794c21ecb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escolha como deseja executar o programa:\n",
      "1 - Rodar no terminal\n",
      "2 - Rodar com Streamlit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Digite sua escolha (1 ou 2):  2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_sql_agent, AgentType\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_community.callbacks.manager import get_openai_callback\n",
    "from langchain.agents import Tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from pydantic import BaseModel\n",
    "from getpass import getpass\n",
    "\n",
    "\n",
    "\n",
    "def search_responses_csv(query):\n",
    "    csv_file_path = \"responses.csv\"\n",
    "    if os.path.isfile(csv_file_path):\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        matching_rows = df[df['query'].str.contains(query, case=False, na=False)]\n",
    "        if not matching_rows.empty:\n",
    "            return matching_rows.iloc[0]['response']\n",
    "    return None\n",
    "\n",
    "def setup_environment_and_agent():\n",
    "    # Get the directory of the current script\n",
    "    #script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    script_dir = os.getcwd()  # Obtém o diretório de trabalho atual\n",
    "    env_file = 'inf.env'\n",
    "    env_path = os.path.join(script_dir, env_file)  # Use the script's directory\n",
    "\n",
    "    if not os.path.exists(env_path):\n",
    "        print(f\"Error: '{env_file}' not found at {env_path}. Creating a new one.\")\n",
    "        with open(env_path, 'w') as f:\n",
    "            f.write(\"# Add your OpenAI API key and DB credentials here\\n\")\n",
    "            f.write(\"OPENAI_API_KEY=\\n\")\n",
    "            f.write(\"DB_USER=\\n\")\n",
    "            f.write(\"DB_PASSWORD=\\n\")\n",
    "            f.write(\"DB_HOST=\\n\")\n",
    "            f.write(\"DB_NAME=\\n\")\n",
    "            f.write(\"DB_PORT=5432\\n\")\n",
    "        print(f\"Please edit '{env_path}' with your credentials and rerun the script.\")\n",
    "        exit(1)\n",
    "\n",
    "    if not load_dotenv(env_path):\n",
    "        print(f\"Warning: Failed to load environment variables from '{env_path}'.\")\n",
    "\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key:\n",
    "        openai_api_key = getpass(\"Enter your OpenAI API key: \")\n",
    "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "        with open(env_path, 'a') as f:\n",
    "            f.write(f\"OPENAI_API_KEY={openai_api_key}\\n\")\n",
    "\n",
    "    db_user = os.getenv(\"DB_USER\")\n",
    "    db_password = os.getenv(\"DB_PASSWORD\")\n",
    "    db_host = os.getenv(\"DB_HOST\")\n",
    "    db_name = os.getenv(\"DB_NAME\")\n",
    "    db_port = os.getenv(\"DB_PORT\", \"5432\")\n",
    "\n",
    "    SQLALCHEMY_DATABASE_URL = f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "    engine = create_engine(SQLALCHEMY_DATABASE_URL)\n",
    "    db = SQLDatabase.from_uri(SQLALCHEMY_DATABASE_URL, schema=\"tarifas\")\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5)\n",
    "    toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "    csv_tool = Tool(\n",
    "        name=\"SearchResponsesCSV\",\n",
    "        func=search_responses_csv,\n",
    "        description=\"Search for previous responses in the 'responses.csv' file based on the user's query.\"\n",
    "    )\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    Seu objetivo é auxiliar os usuários com suas consultas. Você tem acesso a duas fontes principais de informação:\n",
    "    1. O banco de dados SQL 'sql_bot' para consultas relacionadas a tarifas e cálculos.\n",
    "    2. O arquivo 'responses.csv', que contém respostas previamente geradas para consultas anteriores.\n",
    "    **Instruções gerais**:\n",
    "    - Primeiro, verifique se a consulta do usuário já foi respondida no 'responses.csv' usando a ferramenta 'SearchResponsesCSV'. Se encontrar uma resposta correspondente, retorne-a diretamente ao usuário.\n",
    "    - Se não houver resposta no 'responses.csv', processe a consulta normalmente usando o banco de dados SQL ou gere uma resposta conversacional, conforme apropriado.\n",
    "    - Para consultas relacionadas ao banco de dados, forneça respostas detalhadas em formato tabular. Se o resultado puder ser grande, limite a um subconjunto (ex.: 10 primeiros registros) e informe o usuário.\n",
    "    - Para consultas não relacionadas ao banco de dados, responda de forma amigável e conversacional.\n",
    "    - Não realize alterações no banco de dados, apenas consultas (SELECT).\n",
    "    **Cálculos específicos**:\n",
    "    - Para cálculos como tarifas médias ou yield, use sempre a fórmula da média ponderada deflacionada pelo IPCA, conforme exemplos abaixo.\n",
    "    - Exemplo de cálculo de tarifa média para janeiro de 2024:\n",
    "    SELECT nm_empresa,\n",
    "    SUM(nr_assentos * nr_tarifa * ipca_base.nr_ipca / ft.nr_ipca) / SUM(nr_assentos) AS tarifa_media_ponderada_deflacionada\n",
    "    FROM \"tarifas\".\"ft_tarifas_domesticas\" ft\n",
    "    CROSS JOIN (SELECT ipca AS nr_ipca\n",
    "    FROM \"tarifas\".\"dm_ipca\"\n",
    "    ORDER BY nr_ano_mes_referencia DESC\n",
    "    LIMIT 1) AS ipca_base\n",
    "    WHERE ft.nr_ano_referencia = 2024 AND ft.nr_mes_referencia = 1\n",
    "    GROUP BY nm_empresa\n",
    "\n",
    "    - Exemplo de cálculo de yield para janeiro de 2024:\n",
    "    SELECT nm_empresa,\n",
    "    SUM(nr_tarifa * nr_ipca_base * nr_assentos / nr_ipca) / SUM(nr_distancia * nr_assentos) AS yield\n",
    "    FROM \"tarifas\".\"ft_tarifas_domesticas\" ft\n",
    "    CROSS JOIN (SELECT nr_ipca AS nr_ipca_base\n",
    "    FROM \"tarifas\".\"ft_tarifas_domesticas\"\n",
    "    ORDER BY nr_ano_referencia DESC, nr_mes_referencia DESC\n",
    "    LIMIT 1) AS ipca_base\n",
    "    WHERE ft.nr_ano_referencia = 2024 AND ft.nr_mes_referencia = 1\n",
    "    GROUP BY nm_empresa\n",
    "\n",
    "    **Regras adicionais**:\n",
    "    - Não informe valores absolutos, sempre a média ponderada, assim se for socitado a tarifa, ou o yield, retorno tarifas e yields podenrados médios, então lembre da divisão pelos assentos!\n",
    "    - Considere a GOL como VRG Linhas Aéreas, GOL LINHAS AÉREAS S.A., ou GLO.\n",
    "    - Para destino-s, priorize sg_icao_origem e sg_icao_destino; se não encontrar, use sg_iata_origem e sg_iata_destino.\n",
    "    - Se o usuario perguntar sobre uma cidade ou um estado, lembre de fazer a reuniao dos aeroportos da cidade ou estado.\n",
    "    - Nunca altere a lógica do CROSS JOIN para o IPCA mais recente.\n",
    "    - A menos que explicitamete solicitado, sempre calcule tarifas e yields médios do setor e separado por empresa.\n",
    "    - Quando perguntado qual a tarifa ou yield, SEMPRE considere o valor médio. NÃO há interesse em saber o valor absoluto DE TARIFA E YIELD.\n",
    "    - Se perguntado sobre a GOl, considere ser a GOL LINHAS AÉREAS S.A. (GLO na coluna sg_empresa_icao) Se pergutando sobre a TAM considere ser a TAM LINHAS AÉREAS S.A. (TAM na coluna sg_empresa_icao) e se perguntado sobre a AZUL, considere ser a AZUL LINHAS AÉREAS BRASILEIRAS S/A (AZU na coluna sg_empresa_icao) \n",
    "    \"\"\"\n",
    "    agent_executor = create_sql_agent(\n",
    "        llm=llm,\n",
    "        toolkit=toolkit,\n",
    "        extra_tools=[csv_tool],\n",
    "        verbose=True,\n",
    "        agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "        system_message=prompt_template\n",
    "    )\n",
    "    return agent_executor, prompt_template\n",
    "\n",
    "def save_response(query, response, memory):\n",
    "    csv_file_path = \"responses.csv\"\n",
    "    data = {\n",
    "        \"query\": [query],\n",
    "        \"response\": [response],\n",
    "        \"memory\": [memory]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    if not os.path.isfile(csv_file_path):\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "    else:\n",
    "        df.to_csv(csv_file_path, mode='a', header=False, index=False)\n",
    "\n",
    "def count_tokens(chain, query, prompt_template):\n",
    "    with get_openai_callback() as cb:\n",
    "        full_query = prompt_template + \"\\nUser query: \" + query\n",
    "        try:\n",
    "            result = chain.run(full_query)\n",
    "            print(f'Spent a total of {cb} tokens')\n",
    "        except Exception as e:\n",
    "            result = \"I don't have sufficient resources to process your query!\"\n",
    "            return e, full_query\n",
    "    return result, full_query\n",
    "\n",
    "# Configuração do agente\n",
    "agent_executor, prompt_template = setup_environment_and_agent()\n",
    "\n",
    "# Função para rodar no terminal\n",
    "def run_terminal():\n",
    "    print(\"Assistente Conversacional de Tarifas Domésticas\")\n",
    "    print(\"Digite sua consulta abaixo (ou 'exit' para sair):\")\n",
    "    \n",
    "    while True:\n",
    "        user_query = input(\"Consulta: \")\n",
    "        if user_query.lower() == 'exit':\n",
    "            print(\"Encerrando o programa. Até logo!\")\n",
    "            break\n",
    "        elif user_query:\n",
    "            print(\"Processando sua consulta...\")\n",
    "            response, memory = count_tokens(agent_executor, user_query, prompt_template)\n",
    "            print(\"\\nResposta do Bot:\")\n",
    "            print(response)\n",
    "            save_choice = input(\"\\nA resposta está correta? (s/n): \").lower()\n",
    "            if save_choice == 's':\n",
    "                save_response(user_query, response, memory)\n",
    "                print(\"Resposta salva com sucesso em 'responses.csv'!\")\n",
    "            else:\n",
    "                print(\"Resposta descartada.\")\n",
    "\n",
    "# Função para rodar no Streamlit\n",
    "def run_streamlit():\n",
    "    st.title(\"Assistente Conversacional de Tarifas Domésticas\")\n",
    "    st.write(\"Digite sua consulta abaixo e receba uma resposta do bot. Você pode salvar respostas aprovadas no arquivo 'responses.csv'.\")\n",
    "\n",
    "    user_query = st.text_input(\"Digite sua consulta (ou 'exit' para sair):\", \"\")\n",
    "    \n",
    "    if st.button(\"Enviar Consulta\"):\n",
    "        if user_query.lower() == 'exit':\n",
    "            st.write(\"Encerrando o aplicativo. Até logo!\")\n",
    "        elif user_query:\n",
    "            with st.spinner(\"Processando sua consulta...\"):\n",
    "                response, memory = count_tokens(agent_executor, user_query, prompt_template)\n",
    "            st.write(\"**Resposta do Bot:**\")\n",
    "            st.write(response)\n",
    "\n",
    "            st.session_state['last_query'] = user_query\n",
    "            st.session_state['last_response'] = response\n",
    "            st.session_state['last_memory'] = memory\n",
    "            st.session_state['show_confirmation'] = True\n",
    "\n",
    "    if 'show_confirmation' in st.session_state and st.session_state['show_confirmation']:\n",
    "        st.write(\"**A resposta está correta?**\")\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            if st.button(\"Sim, salvar\"):\n",
    "                save_response(st.session_state['last_query'], st.session_state['last_response'], st.session_state['last_memory'])\n",
    "                st.success(\"Resposta salva com sucesso em 'responses.csv'!\")\n",
    "                st.session_state['show_confirmation'] = False\n",
    "        with col2:\n",
    "            if st.button(\"Não, descartar\"):\n",
    "                st.warning(\"Resposta descartada.\")\n",
    "                st.session_state['show_confirmation'] = False\n",
    "\n",
    "# Menu de escolha\n",
    "def main():\n",
    "    print(\"Escolha como deseja executar o programa:\")\n",
    "    print(\"1 - Rodar no terminal\")\n",
    "    print(\"2 - Rodar com Streamlit\")\n",
    "    \n",
    "    escolha = input(\"Digite sua escolha (1 ou 2): \")\n",
    "    \n",
    "    if escolha == \"1\":\n",
    "        run_terminal()\n",
    "    elif escolha == \"2\":\n",
    "        # Salva o código Streamlit em um arquivo temporário\n",
    "        with open(\"temp_app.py\", \"w\") as f:\n",
    "            streamlit_code = f\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_sql_agent, AgentType\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_community.callbacks.manager import get_openai_callback\n",
    "from langchain.agents import Tool\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "from getpass import getpass\n",
    "\n",
    "def search_responses_csv(query):\n",
    "    csv_file_path = \"responses.csv\"\n",
    "    if os.path.isfile(csv_file_path):\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        matching_rows = df[df['query'].str.contains(query, case=False, na=False)]\n",
    "        if not matching_rows.empty:\n",
    "            return matching_rows.iloc[0]['response']\n",
    "    return None\n",
    "\n",
    "def setup_environment_and_agent():\n",
    "    env_file = 'inf.env'\n",
    "    env_path = os.path.join(os.path.dirname(__file__), env_file)\n",
    "    if not os.path.exists(env_path):\n",
    "        st.error(f\"'inf.env' not found. Please create it with your credentials.\")\n",
    "        return None, None\n",
    "    load_dotenv(env_path)\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key:\n",
    "        openai_api_key = getpass(\"Enter your OpenAI API key: \")\n",
    "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    db_user = os.getenv(\"DB_USER\")\n",
    "    db_password = os.getenv(\"DB_PASSWORD\")\n",
    "    db_host = os.getenv(\"DB_HOST\")\n",
    "    db_name = os.getenv(\"DB_NAME\")\n",
    "    db_port = os.getenv(\"DB_PORT\", \"5432\")\n",
    "    SQLALCHEMY_DATABASE_URL = f\"postgresql://{{db_user}}:{{db_password}}@{{db_host}}:{{db_port}}/{{db_name}}\"\n",
    "    engine = create_engine(SQLALCHEMY_DATABASE_URL)\n",
    "    db = SQLDatabase.from_uri(SQLALCHEMY_DATABASE_URL, schema=\"tarifas\")\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5)\n",
    "    toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "    csv_tool = Tool(\n",
    "        name=\"SearchResponsesCSV\",\n",
    "        func=search_responses_csv,\n",
    "        description=\"Search for previous responses in the 'responses.csv' file.\"\n",
    "    )\n",
    "    prompt_template = \\\"\\\"\\\"{prompt_template}\\\"\\\"\\\"\n",
    "    agent_executor = create_sql_agent(\n",
    "        llm=llm,\n",
    "        toolkit=toolkit,\n",
    "        extra_tools=[csv_tool],\n",
    "        verbose=True,\n",
    "        agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "        system_message=prompt_template\n",
    "    )\n",
    "    return agent_executor, prompt_template\n",
    "\n",
    "def save_response(query, response, memory):\n",
    "    csv_file_path = \"responses.csv\"\n",
    "    data = {{\"query\": [query], \"response\": [response], \"memory\": [memory]}}\n",
    "    df = pd.DataFrame(data)\n",
    "    if not os.path.isfile(csv_file_path):\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "    else:\n",
    "        df.to_csv(csv_file_path, mode='a', header=False, index=False)\n",
    "\n",
    "def count_tokens(chain, query, prompt_template):\n",
    "    with get_openai_callback() as cb:\n",
    "        full_query = prompt_template + \"\\\\nUser query: \" + query\n",
    "        try:\n",
    "            result = chain.run(full_query)\n",
    "            st.text(f'Spent a total of {{cb}} tokens')\n",
    "        except Exception as e:\n",
    "            result = \"I don't have sufficient resources to process your query!\"\n",
    "            return e, full_query\n",
    "    return result, full_query\n",
    "\n",
    "agent_executor, prompt_template = setup_environment_and_agent()\n",
    "\n",
    "if agent_executor:\n",
    "    st.title(\"Assistente GEAC - IA\")\n",
    "    st.write(\"Digite sua consulta abaixo e receba uma resposta do bot.\")\n",
    "    user_query = st.text_input(\"Digite sua consulta (ou 'exit' para sair):\", \"\")\n",
    "    if st.button(\"Enviar Consulta\"):\n",
    "        if user_query.lower() == 'exit':\n",
    "            st.write(\"Encerrando o aplicativo. Até logo!\")\n",
    "        elif user_query:\n",
    "            with st.spinner(\"Processando sua consulta...\"):\n",
    "                response, memory = count_tokens(agent_executor, user_query, prompt_template)\n",
    "            st.write(\"**Resposta do Bot:**\")\n",
    "            st.write(response)\n",
    "            st.session_state['last_query'] = user_query\n",
    "            st.session_state['last_response'] = response\n",
    "            st.session_state['last_memory'] = memory\n",
    "            st.session_state['show_confirmation'] = True\n",
    "    if 'show_confirmation' in st.session_state and st.session_state['show_confirmation']:\n",
    "        st.write(\"**A resposta está correta?**\")\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            if st.button(\"Sim, salvar\"):\n",
    "                save_response(st.session_state['last_query'], st.session_state['last_response'], st.session_state['last_memory'])\n",
    "                st.success(\"Resposta salva com sucesso em 'responses.csv'!\")\n",
    "                st.session_state['show_confirmation'] = False\n",
    "        with col2:\n",
    "            if st.button(\"Não, descartar\"):\n",
    "                st.warning(\"Resposta descartada.\")\n",
    "                st.session_state['show_confirmation'] = False\n",
    "\"\"\"\n",
    "            # Escreve o código no arquivo com o prompt_template escapado\n",
    "            f.write(streamlit_code.replace(\"{prompt_template}\", prompt_template.replace('\"', '\\\\\"')))\n",
    "        # Executa o Streamlit\n",
    "        os.system(\"streamlit run temp_app.py\")\n",
    "    else:\n",
    "        print(\"Escolha inválida! Por favor, digite 1 ou 2.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
